# Multi-Agent-Systems
Designing, developing and deploying multi agent systems

Topics covered in this project:
- Building a Multi Agent System
- Managing AI Agents at different scales (scaling systems)
- Evaluating Agent System's performance

# Module 1
## Foundation of AI Agents
3 Importent Pillars:
1) Easy to Build
2) Reliable
3) Easy to Manage and Scale

### What are AI Agents?
AI Systems that can decide what happens next in order to achieve a goal.
The ability of an LLM to make reasonable choices, instead of just generating content. In short, to have cognition ability.

- AI controls the application flow.
- Cognition, Real Time, Self Healing (fixes something if it breaks), Self Improvement (learn from what it does)

#### How do AI Agents differ from classic LLMs?
LLMs have an ability to create (write emails, create images, evaluate reports. generate videos)
AI Agents have the ability to decide (what tools and data to use, how to recover from failures)


### Use Cases of AI Agents
Does the use case favor complexity or precision.

Spectrum of Agency: <br>
       LLM -> Agent -> Crew <br>
Low Agency --------> High Agency



## What makes an AI Agent intelligent?

1) Traditional AI Systems:
You have features and labels to train your model on. The more training samples you have, the better the model understands the correlation between the the features and the target variable. 

2) LLMs
Prompt = Features
The prompt that you provide itself act as the features. And the answer provided by the model is the predicted answer or response to the input. 
Hence, better the prompt, better the output you can expect.

Traditional Strongly Typed Software
You know what you provide as an input, you know the transformations and you have a deterministic output.

In agentic systems (LLMs), you can provide any input, the transformations are partially a black box and you can only expect the data that may be outputted.
What goes into the LLM (input) heavily impacts how it responds.


**Context Engineering:**
Deciding the best possible input to get the required output.
Optimizing the input

Components of Context Engineering:
1) System Prompts - provide guidence on how LLMs should behave
2) Clear instructions
3) Role Playing 
4) Memory
5) Tools 

So to create a job listing:
Input: Job Role
Agent Roles: Researcher, Writer, Editor
Output: Job Posting



# Module 2

## Controlling Agents
How to provide deterministic controls on probabilistic agents?

1) Memory - Dynamically update context to help agents learn and get better over time.

2) Guardrails - Adding either deterministic or probabilistic (LLM as judge or code file (like a test file)) checks on the output.

3) Hooks - Execute deterministic code either before or after Agents.


### Agentic Memory
Mainly 3 types:
1) Short Term <br>
**Stores data from past executions to add context** that gets shared among agents
2) Long Term <br>
**Helps agents to self refect and improve over time.** So when these agents get donw with their tasks, they compare their out put with
the expected output (on getting feedback from the user), extract the learnings and store this data for later usage. So when they run
the same task later, they understand what they can do better.
3) Entity <br>
Collect facts about people, companies, locations, products etc. So say there is a paragraph generated by ChatGPT. So the entities are:
- Persons -> John, Rachel
- Organizations -> Walmart, Microsoft
- Locations -> Denmark, China


There are mainly 2 types of memory update:
1) Generating Memories - executing multiple times and data getting stored in the memory databases
2) Training with feedback - you provide clear guidance on what are the agents doing right or wrong.

### Agentic Memory v/s Agentic Knowledge
1) Agentic Memory
- Internal information is influenced be previous executions
- Data is selectively added to agent's context during execution
- Memory is updated from feedback by human or LLMs as judge

2) Agentic Knowledge
- External informaltion retrieved from different sources.
- Data is selectively added to agent's context from flat files or vector databases
- It is not updated from feedback (pre-added during runtime)


### Guardrails
- allow you to add more deterministic control over agents.
- For most usecases, you need specific answers (reliable outcomes every time you rerun).
- allow you to validate the information midway through a process, they alos allow you to inject feedback back into the loop (when the answer is not as expected and it rejects the answers).

- There are 2 types of guardrails:
1) LLM - easy to build
2) Code - allows you to be as specific as you want (hard requirements)


You can enforcing structured outputs using Pydantic and Formatter agents

### Execution Hooks
Allow you to run code before or after the agent executions.
For example: loading data -> modification of inputs -> feeding to agents -> modifying output -> pushing to database
Before Hooks look like:
- Fetching input data
- Cleaning the data
- Scraping personal information from inputs

After Hooks:
- Validate outputs
- Moderate output content
- Log outputs

Examples of Before and After Hooks:
```python
# PRE HOOK FUNCTION
def format_phone_numbers(inputs):
       phone = inputs.get("phone_num", "")
       digits = ''.join(filter(str.isdigit, phone))
       formatted = f"({digits[:3]}) {digits[3:6]}-{digits[6:]}"
       inputs['phone_num'] = formatted
       return inputs


# POST HOOK FUNCTION
def confirmation(outputs):
       phone = outputs.get("phone_num", "")
       safe_display = "(XXX) XXX-" + phone[-4:]
       confirmation = f"Phone number {safe_display} successfully processed"
       return confirmation
```

## Using tools in Agents

 
