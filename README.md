# Multi-Agent-Systems
Designing, developing and deploying multi agent systems

Topics covered in this project:
- Building a Multi Agent System
- Managing AI Agents at different scales (scaling systems)
- Evaluating Agent System's performance

# Module 1
## Foundation of AI Agents
3 Importent Pillars:
1) Easy to Build
2) Reliable
3) Easy to Manage and Scale

### What are AI Agents?
AI Systems that can decide what happens next in order to achieve a goal.
The ability of an LLM to make reasonable choices, instead of just generating content. In short, to have cognition ability.

AI controls the application flow.

Cognition, Real Time, Self Healing (fixes something if it breaks), Self Improvement (learn from what it does)

#### How do AI Agents differ from classic LLMs?
LLMs have an ability to create (write emails, create images, evaluate reports. generate videos)

AI Agents have the ability to decide (what tools and data to use, how to recover from failures)


### Use Cases of AI Agents
Does the use case favor complexity or precision.

Spectrum of Agency:
       LLM -> Agent -> Crew
Low Agency --------> High Agency



## What makes an AI Agent intelligent?

1) Traditional AI Systems:
You have features and labels to train your model on. The more training samples you have, the better the model understands the correlation between the the features and the target variable. 

2) LLMs
Prompt = Features
The prompt that you provide itself act as the features. And the answer provided by the model is the predicted answer or response to the input. 
Hence, better the prompt, better the output you can expect.

Traditional Strongly Typed Software
You know what you provide as an input, you know the transformations and you have a deterministic output.

In agentic systems (LLMs), you can provide any input, the transformations are partially a black box and you can only expect the data that may be outputted.
What goes into the LLM (input) heavily impacts how it responds.


**Context Engineering:**
Deciding the best possible input to get the required output.
Optimizing the input

Components of Context Engineering:
1) System Prompts - provide guidence on how LLMs should behave
2) Clear instructions
3) Role Playing 
4) Memory
5) Tools 

So to create a job listing:
Input: Job Role
Agent Roles: Researcher, Writer, Editor
Output: Job Posting



# Module 2

## Controlling Agents
How to provide deterministic controls on probabilistic agents?

1) Memory
- Dynamically update context to help agents learn and get better over time.

2) Guardrails
- Adding either deterministic or probabilistic (LLM as judge or code file (like a test file)) checks on the output.

3) Hooks
- Execute deterministic code either before or after Agents.


### Agentic Memory
Mainly 3 types:
1) Short Term
**Stores data from past executions to add context** that gets shared among agents
2) Long Term 
**Helps agents to self refect and improve over time.** So when these agents get donw with their tasks, they compare their out put with
the expected output (on getting feedback from the user), extract the learnings and store this data for later usage. So when they run
the same task later, they understand what they can do better.
3) Entity
Collect facts about people, companies, locations, products etc. So say there is a paragraph generated by ChatGPT. So the entities are:
- Persons -> John, Rachel
- Organizations -> Walmart, Microsoft
- Locations -> Denmark, China


There are mainly 2 types of memory update:
1) Generating Memories - executing multiple times and data getting stored in the memory databases
2) Training with feedback - you provide clear guidance on what are the agents doing right or wrong.

### Agentic Memory v/s Agentic Knowledge
1) Agentic Memory
- Internal information is influenced be previous executions
- Data is selectively added to agent's context during execution
- Memory is updated from feedback by human or LLMs as judge

2) Agentic Knowledge
- External informaltion retrieved from different sources.
- Data is selectively added to agent's context from flat files or vector databases
- It is not updated from feedback (pre-added during runtime)


### Guardrails
- allow you to add more deterministic control over agents.
- For most usecases, you need specific answers (reliable outcomes every time you rerun).
- allow you to validate the information midway through a process, they alos allow you to inject feedback back into the loop (when the answer is not as expected and it rejects the answers).

- There are 2 types of guardrails:
1) LLM - easy to build
2) Code - allows you to be as specific as you want (hard requirements)


You can enforcing structured outputs using Pydantic and Formatter agents

### Execution Hooks
Allow you to run code before or after the agent executions.
For example: loading data -> modification of inputs -> feeding to agents -> modifying output -> pushing to database
Before Hooks look like:
- Fetching input data
- Cleaning the data
- Scraping personal information from inputs

After Hooks:
- Validate outputs
- Moderate output content
- Log outputs

Examples of Before and After Hooks:
```python
# PRE HOOK FUNCTION
def format_phone_numbers(inputs):
       phone = inputs.get("phone_num", "")
       digits = ''.join(filter(str.isdigit, phone))
       formatted = f"({digits[:3]}) {digits[3:6]}-{digits[6:]}"
       inputs['phone_num'] = formatted
       return inputs


# POST HOOK FUNCTION
def confirmation(outputs):
       phone = outputs.get("phone_num", "")
       safe_display = "(XXX) XXX-" + phone[-4:]
       confirmation = f"Phone number {safe_display} successfully processed"
       return confirmation
```

## Using tools in Agents
They help in establishing connections with external resources and allow us to fetch or push 
data to these resources. 
Some Use Cases of these tools:
- Go through Files and Folders in the File System
- Web Scraping and Browsing
- Database Connections
- Code Execution

### Considerations for Tool Calling
1) **Error Handling** - building robust Exceptions for gracefully handling failures.
2) **Caching** - cross agent caching to optimize performance and reduce redundant operations.
3) **Asynchronous support**

You can either give tools to the agents or assign tools to the tasks itself that required to accomplish that specific task only.

### Components of Tools
There are 2 components:
1) Simple interface 
       - name
       - description
       - inputs
2) Custom Code
       - authentication
       - API calling
       - service connection

For instance, consider creating a CUSTOM *Website Scraping Tool* <br>
*Name*: Read Website Content <br>
*Description*: A tool that can be used to read the content from the provided website <br>
*Inputs*: {website_url : str} <br>

*Custom code*: Simple scraping logic using http requests. <br>

 ```python

       import requests
       from crewai_tools import tool

       @tool("Read website content")
       def read_website_content(website_url: str) -> str:
              """ A tools that reads content from a website"""  # <--- Tool Description
              try:
                     response = requests.get(website_url, timeout=5)
                     response.raise_for_status()
                     return response.text
              exception e:
                     return f"Failed to read website: {str(e)}"


       from crewai import Agent

       agent = Agent(
              role='Web Reader',
              goal = 'Understand and summarize content from websites',
              backstory = 'You specialize in reading and summarizing website content',
              tools = [read_website_content],
              verbose = True,
              memory = True
       )

 ```

We can also use the BUILT IN ENTERPRISE CONNECTORS:

```python

from crewai import Agent
from crewai_tools import CrewaiEnterpriseTools

# Get the Enterprise tool (Gmail tool)
ent_tool = CrewaiEnterpriseTools(enterprise_token = "your_enterprise_token")

# Create an agent with Gmail capabilities
email_agent = Agent(
       role = "Email Manager",
       goal = "Manage and Organize email communications",
       backstory = "An AI assistant specialized in emails",
       tools = [ent_tool]
)

```


### Tool Reliability
How to configure tools for reliable run time behavior?

1) Force Return
- Directly return the output of the tool so that the agent does not mess with it
- specify return_direct = True in agent construction

2) Rate Limits
- Use retry login and set max usage limits to help agents recover from temporary failures and prevent infinite loops.
- Since some built in tools come with hard requirements in terms of how many requests you can make in a certain period of time.

3) Tool Repository
- Promotes reuse and sharing of tools across multiple agents and tasks